{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obsidian News Digest -prototype\n",
    "\n",
    "In this notebook, we'll build an automated news digest tool step by step. You'll implement each component with guidance, run the code to see results, and gradually build a complete working system.\n",
    "\n",
    "Our tool will:\n",
    "- Fetch news articles from popular sources\n",
    "- Summarize articles using LangChain and a language model\n",
    "- Format summaries in Markdown\n",
    "- Save the digest to an Obsidian vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration loaded\n",
      "📁 Output path: D:\\Obsidian_VauLTs\\My_Daily_newS__\\Daily_news\n",
      "📰 News sources: 2 sources configured\n",
      "📊 Max articles: 10\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: CONFIGURATIONS\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if required environment variables are set\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "vault_path = os.getenv(\"OBSIDIAN_VAULT_PATH\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"⚠️ OPENAI_API_KEY not found! Make sure to set it in your .env file.\")\n",
    "    \n",
    "    \n",
    "if not vault_path:\n",
    "    print(\"⚠️ OBSIDIAN_VAULT_PATH not found! Make sure to set it in your .env file.\")\n",
    "    \n",
    "    vault_path = \"./output\"  # Default output folder\n",
    "    \n",
    "# Configuration variables\n",
    "news_sources = [\n",
    "    \"https://www.apnews.com/\",\n",
    "    \"https://www.c-span.org/\"\n",
    "]\n",
    "max_articles = 10  # Maximum number of articles in the digest\n",
    "output_folder = \"Daily_news\"  # Folder within Obsidian vault\n",
    "\n",
    "print(\"✅ Configuration loaded\")\n",
    "print(f\"📁 Output path: {os.path.join(vault_path, output_folder)}\")\n",
    "print(f\"📰 News sources: {len(news_sources)} sources configured\")\n",
    "print(f\"📊 Max articles: {max_articles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: FETCHING NEWS\n",
    "\n",
    "# Import newspaper3k library\n",
    "from newspaper import Article, build\n",
    "\n",
    "def fetch_news(source_urls: List[str], max_articles_per_source: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch news articles from multiple sources using newspaper3k.\n",
    "    \n",
    "    Args:\n",
    "        source_urls: List of news source URLs to fetch from\n",
    "        max_articles_per_source: Maximum number of articles to fetch per source\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing article information\n",
    "    \"\"\"\n",
    "    all_articles = []\n",
    "    \n",
    "    for url in source_urls:\n",
    "        try:\n",
    "            print(f\"Fetching from {url}...\")\n",
    "            \n",
    "            # Build newspaper from source URL - this analyzes the site to find articles\n",
    "            paper = build(url)\n",
    "            \n",
    "            # Get all article URLs from the source\n",
    "            article_urls = paper.article_urls()\n",
    "            print(f\"Found {len(article_urls)} article links\")\n",
    "            \n",
    "            # Get the most recent/prominent articles \n",
    "            article_urls_list = list(article_urls)\n",
    "            # Most news sites list headlines/important articles first in their HTML\n",
    "            sampled_urls = article_urls_list[:min(max_articles_per_source * 2, len(article_urls_list))]     \n",
    "            \n",
    "            source_articles = []\n",
    "            for article_url in sampled_urls:\n",
    "                try:\n",
    "                    # Create an article object\n",
    "                    article = Article(article_url)\n",
    "                    \n",
    "                    # Download the article content\n",
    "                    article.download()\n",
    "                    time.sleep(1)  # Pause briefly to be polite to the server\n",
    "                    \n",
    "                    # Parse the article to extract content\n",
    "                    article.parse()\n",
    "                    \n",
    "                    # Skip articles with minimal content (likely not full articles)\n",
    "                    if not article.text or len(article.text) < 100:\n",
    "                        continue\n",
    "                        \n",
    "                    # Add article information to our collection\n",
    "                    source_articles.append({\n",
    "                        \"title\": article.title,\n",
    "                        \"url\": article.url,\n",
    "                        \"text\": article.text[:2000],  # Limit text length for LLM (saves tokens)\n",
    "                        \"published_date\": article.publish_date,\n",
    "                        \"source\": url\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"✓ Downloaded: {article.title[:50]}...\")\n",
    "                    \n",
    "                    # Stop once we have enough articles from this source\n",
    "                    if len(source_articles) >= max_articles_per_source:\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing article {article_url}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Add articles from this source to our master list\n",
    "            all_articles.extend(source_articles)\n",
    "            print(f\"Got {len(source_articles)} articles from {url}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing source {url}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testing news fetcher...\n",
      "Fetching from https://www.naftemporiki.gr/...\n",
      "Found 2 article links\n",
      "✓ Downloaded: Η Ελλάδα αναλαμβάνει την Προεδρία του Συμβουλίου Α...\n",
      "Got 1 articles from https://www.naftemporiki.gr/\n",
      "\n",
      "Retrieved 1 articles\n",
      "\n",
      "SAMPLE ARTICLE:\n",
      "Title: Η Ελλάδα αναλαμβάνει την Προεδρία του Συμβουλίου Ασφαλείας του ΟΗΕ\n",
      "URL: https://www.naftemporiki.gr/politics/1950756/i-ellada-analamvanei-tin-proedria-toy-symvoylioy-asfaleias-toy-oie/\n",
      "Text length: 692 characters\n",
      "Text preview: Την Προεδρία του Συμβουλίου Ασφαλείας του Οργανισμού Ηνωμένων Εθνών (ΟΗΕ) αναλαμβάνει από αύριο, 1η Μαΐου 2025, η Ελλάδα και αναμένεται να διαρκέσει ένα μήνα.\n",
      "\n",
      "Σύμφωνα με πληροφορίες της «Ν», στις 20 ...\n"
     ]
    }
   ],
   "source": [
    "# Test the news fetcher with a single source and limited articles\n",
    "test_source = [news_sources[0]]  # Just use the first source (BBC)\n",
    "print(\"🔍 Testing news fetcher...\")\n",
    "test_articles = fetch_news(test_source, max_articles_per_source=1)\n",
    "\n",
    "# Print information about the retrieved articles\n",
    "print(f\"\\nRetrieved {len(test_articles)} articles\")\n",
    "if test_articles:\n",
    "    article = test_articles[0]\n",
    "    print(f\"\\nSAMPLE ARTICLE:\")\n",
    "    print(f\"Title: {article['title']}\")\n",
    "    print(f\"URL: {article['url']}\")\n",
    "    print(f\"Text length: {len(article['text'])} characters\")\n",
    "    print(f\"Text preview: {article['text'][:200]}...\")\n",
    "else:\n",
    "    print(\"No articles found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: SUMMARIZING NEWS\n",
    "\n",
    "# Import LangChain components\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def summarize_and_format_articles(articles: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"\n",
    "    Summarize news articles and format them as a complete markdown digest.\n",
    "    \n",
    "    Args:\n",
    "        articles: List of article dictionaries with title, text, etc.\n",
    "        \n",
    "    Returns:\n",
    "        Formatted markdown string of the complete digest\n",
    "    \"\"\"\n",
    "    # Initialize the OpenAI chat model\n",
    "    llm = ChatOpenAI(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        model=\"gpt-4.1-nano-2025-04-14\", \n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    # Get today's date for the digest header\n",
    "    today = datetime.now().strftime(\"%d %b %Y\")\n",
    "    \n",
    "    # Handle case with no articles\n",
    "    if not articles:\n",
    "        return f\"No major news today.\"\n",
    "    \n",
    "    # Process each article\n",
    "    article_summaries = []\n",
    "    for i, article in enumerate(articles):\n",
    "        try:\n",
    "            print(f\"Summarizing article {i+1}/{len(articles)}...\")\n",
    "            \n",
    "            # Extract source domain for display\n",
    "            source_url = article['source']\n",
    "            source_domain = source_url.split('//')[1].split('/')[0].replace('www.', '')\n",
    "            \n",
    "            # Create prompt template for article summarization with formatting\n",
    "            prompt = ChatPromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                You are a Veteran News Journalist.\n",
    "                Summarize this news article in 5 sentences. \n",
    "                Focus on the main facts and key details.\n",
    "                \n",
    "                Title: {title}\n",
    "                \n",
    "                Article: {text}\n",
    "                \n",
    "                Format your response in this exact format:\n",
    "                \n",
    "                ## {title}\n",
    "                \n",
    "                [Your 5 sentence summary here]\n",
    "                \n",
    "                *Source: {source_domain}*\n",
    "                \n",
    "                [Read more ↗]({url})\n",
    "                \n",
    "                ---\n",
    "                \"\"\"\n",
    "            )\n",
    "            \n",
    "            # Create and invoke the chain (prompt -> LLM)\n",
    "            chain = prompt | llm\n",
    "            response = chain.invoke({\n",
    "                \"title\": article[\"title\"], \n",
    "                \"text\": article[\"text\"],\n",
    "                \"source_domain\": source_domain,\n",
    "                \"url\": article[\"url\"]\n",
    "            })\n",
    "            \n",
    "            # Add the formatted summary to our list\n",
    "            article_summaries.append(response.content)\n",
    "            print(f\"✓ Summarized: {article['title'][:50]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing article '{article['title']}': {e}\")\n",
    "            # Add a placeholder for failed articles\n",
    "            article_summaries.append(f\"## {article['title']}\\n\\nSummary unavailable.\\n\\n---\\n\")\n",
    "    \n",
    "    # Combine everything - note that we're NOT adding the title header\n",
    "    # The filename will serve as the title in Obsidian\n",
    "    digest = \"\\n\".join(article_summaries)\n",
    "    \n",
    "    return digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing summarization...\n",
      "Summarizing article 1/1...\n",
      "✓ Summarized: Η Ελλάδα αναλαμβάνει την Προεδρία του Συμβουλίου Α...\n",
      "\n",
      "Generated digest:\n",
      "-------------------\n",
      "## Η Ελλάδα αναλαμβάνει την Προεδρία του Συμβουλίου Ασφαλείας του ΟΗΕ\n",
      "\n",
      "Από αύριο, 1η Μαΐου 2025, η Ελλάδα θα αναλάβει την Προεδρία του Συμβουλίου Ασφαλείας του ΟΗΕ, με αναμενόμενη διάρκεια ένα μήνα. Στις 20 Μαΐου 2025, θα πραγματοποιηθεί στις Ηνωμένες Πολιτείες Αμερικής κεντρική εκδήλωση της Ελληνικής Προεδρίας, με την παρουσία του Πρωθυπουργού Κυριάκου Μητσοτάκη. Η κεντρική εκδήλωση θα είναι η Συνεδρίαση του ΟΗΕ με θέμα την θαλάσσια ασφάλεια. Ο Πρωθυπουργός θα απευθύνει ομιλία και θα προεδρεύσει της Συνεδρίασης του Συμβουλίου Ασφαλείας του ΟΗΕ στη Νέα Υόρκη.\n"
     ]
    }
   ],
   "source": [
    "# Test with one of the articles we just fetched\n",
    "if test_articles and api_key:\n",
    "    print(\"Testing summarization...\")\n",
    "    digest = summarize_and_format_articles([test_articles[0]])\n",
    "    print(\"\\nGenerated digest:\")\n",
    "    print(\"-------------------\")\n",
    "    print(digest)\n",
    "else:\n",
    "    print(\"Cannot test summarization: No articles or API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: PUBLISHING TO OBSIDIAN\n",
    "\n",
    "def publish_to_obsidian(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Publish the formatted digest to Obsidian vault.\n",
    "    \n",
    "    Args:\n",
    "        content: Formatted markdown content\n",
    "        \n",
    "    Returns:\n",
    "        Path to the created file\n",
    "    \"\"\"\n",
    "    # Get today's date for the filename\n",
    "    today = datetime.now().strftime(\"%d %b %Y\")\n",
    "    \n",
    "    # Create path to the output folder in the vault\n",
    "    folder_path = os.path.join(vault_path, output_folder)\n",
    "    \n",
    "    # Create folder if it doesn't exist\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Create file path with a clear descriptive name\n",
    "    file_name = f\"Global News Digest – {today}.md\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Write content to file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application\n",
    "\n",
    "def create_news_digest(sources=None, max_articles_count=None):\n",
    "    \"\"\"\n",
    "    Execute the complete news digest workflow\n",
    "    \"\"\"\n",
    "    # Use provided parameters or defaults\n",
    "    if sources is None:\n",
    "        sources = news_sources\n",
    "        \n",
    "    if max_articles_count is None:\n",
    "        max_articles_count = max_articles\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Fetch news articles\n",
    "        print(f\"📰 Fetching news from {len(sources)} sources...\")\n",
    "        articles = fetch_news(sources, max_articles_per_source=max_articles_count//len(sources))\n",
    "        print(f\"Retrieved {len(articles)} articles.\")\n",
    "        \n",
    "        # Take top articles if we have more than max_articles_count\n",
    "        selected_articles = articles[:max_articles_count]\n",
    "        print(f\"Selected {len(selected_articles)} articles for summarization.\")\n",
    "        \n",
    "        # Step 2: Summarize and format articles\n",
    "        print(\"🔍 Summarizing and formatting articles...\")\n",
    "        digest = summarize_and_format_articles(selected_articles)\n",
    "        \n",
    "        # Step 3: Publish to Obsidian\n",
    "        print(\"💾 Publishing to Obsidian...\")\n",
    "        file_path = publish_to_obsidian(digest)\n",
    "        \n",
    "        print(f\"✅ News digest published successfully to: {file_path}\")\n",
    "        return file_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in news digest pipeline: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📰 Fetching news from 1 sources...\n",
      "Fetching from https://www.naftemporiki.gr/...\n",
      "Found 0 article links\n",
      "Got 0 articles from https://www.naftemporiki.gr/\n",
      "Retrieved 0 articles.\n",
      "Selected 0 articles for summarization.\n",
      "🔍 Summarizing and formatting articles...\n",
      "💾 Publishing to Obsidian...\n",
      "✅ News digest published successfully to: D:\\Obsidian_VauLTs\\My_Daily_newS__\\Daily_news\\Global News Digest – 30 Apr 2025.md\n",
      "\n",
      "🎉 Success! Your news digest is ready at: D:\\Obsidian_VauLTs\\My_Daily_newS__\\Daily_news\\Global News Digest – 30 Apr 2025.md\n",
      "Check your Obsidian vault to see the complete digest.\n"
     ]
    }
   ],
   "source": [
    "# Run the workflow with just one source and a small number of articles\n",
    "test_workflow_result = create_news_digest(\n",
    "    sources=[news_sources[0]],  # Just use BBC for testing\n",
    "    max_articles_count=2  # Limit to 2 articles for quick testing\n",
    ")\n",
    "\n",
    "if test_workflow_result:\n",
    "    print(f\"\\n🎉 Success! Your news digest is ready at: {test_workflow_result}\")\n",
    "    print(\"Check your Obsidian vault to see the complete digest.\")\n",
    "else:\n",
    "    print(\"\\n❌ Workflow failed. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📰 Fetching news from 2 sources...\n",
      "Fetching from https://www.apnews.com/...\n",
      "Found 148 article links\n",
      "✓ Downloaded: Kremlin says a deal to end the war with Ukraine ca...\n",
      "✓ Downloaded: Vietnam celebrates 50 years since war’s end with f...\n",
      "✓ Downloaded: Middle East latest: At least 12 killed overnight b...\n",
      "✓ Downloaded: Immigrants working legally in the Texas Panhandle ...\n",
      "✓ Downloaded: Takeaways from AP’s report on how Trump’s immigrat...\n",
      "Got 5 articles from https://www.apnews.com/\n",
      "Fetching from https://www.c-span.org/...\n",
      "Found 0 article links\n",
      "Got 0 articles from https://www.c-span.org/\n",
      "Retrieved 5 articles.\n",
      "Selected 5 articles for summarization.\n",
      "🔍 Summarizing and formatting articles...\n",
      "Summarizing article 1/5...\n",
      "✓ Summarized: Kremlin says a deal to end the war with Ukraine ca...\n",
      "Summarizing article 2/5...\n",
      "✓ Summarized: Vietnam celebrates 50 years since war’s end with f...\n",
      "Summarizing article 3/5...\n",
      "✓ Summarized: Middle East latest: At least 12 killed overnight b...\n",
      "Summarizing article 4/5...\n",
      "✓ Summarized: Immigrants working legally in the Texas Panhandle ...\n",
      "Summarizing article 5/5...\n",
      "✓ Summarized: Takeaways from AP’s report on how Trump’s immigrat...\n",
      "💾 Publishing to Obsidian...\n",
      "✅ News digest published successfully to: D:\\Obsidian_VauLTs\\My_Daily_newS__\\Daily_news\\Global News Digest – 30 Apr 2025.md\n",
      "\n",
      "🎉 Success! Your complete news digest is ready at: D:\\Obsidian_VauLTs\\My_Daily_newS__\\Daily_news\\Global News Digest – 30 Apr 2025.md\n",
      "Check your Obsidian vault to see the full digest.\n"
     ]
    }
   ],
   "source": [
    "# Run the complete workflow with all configured sources and max articles\n",
    "full_workflow_result = create_news_digest()\n",
    "\n",
    "if full_workflow_result:\n",
    "    print(f\"\\n🎉 Success! Your complete news digest is ready at: {full_workflow_result}\")\n",
    "    print(\"Check your Obsidian vault to see the full digest.\")\n",
    "else:\n",
    "    print(\"\\n❌ Complete workflow failed. Check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
